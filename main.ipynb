{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\n",
    "!pip install llama-index\n",
    "!pip install llama-index-llms-groq\n",
    "!pip install llama-index-embeddings-huggingface\n",
    "!pip install llama-parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "\n",
    "llm = Groq(model=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "\n",
    ")\n",
    "\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://root:%s@localhost:3306/doctorsapp\" % quote_plus(\"1234hello1234\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SQLDatabase\n",
    "\n",
    "sql_database = SQLDatabase(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.struct_store import NLSQLTableQueryEngine\n",
    "\n",
    "query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"patients\", \"providers\", \"labs\", \"invoices\", \"ledgers\", \"manufacturers\", \"medicines\", \"migrations\", \"model_has_permissions\", \"model_has_roles\", \"options\", \"prescriptions\", \"provider_schedules\", \"providers\", \"vitals\"],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5244002114426781 seconds as it raised InternalServerError: Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the synthesized response:\n",
      "\n",
      "The names of patients are: Marilou Hilpert, Audrey Bartell, Louisa Kautzer, Dillon Lubowitz, Tierra Turcotte, Alphonso Reichert, Louvenia Shields, Fiona Goldner, Marina Schultz, Yadira Upton, Kallie Carroll, Dolly Hirthe, Angelita Renner, Dulce Goyette, and Seth Murray.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.31799298622188943 seconds as it raised InternalServerError: Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.5224021022862977 seconds as it raised InternalServerError: Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a synthesized response based on the query results:\n",
      "\n",
      "\"Marilou Hilpert's vitals are as follows:\n",
      "\n",
      "* Height: 180.11 cm, 183.95 cm, 184.88 cm, and 149.5 cm (multiple readings)\n",
      "* Weight: 50.87 kg, 96.13 kg, 70.57 kg, and 63.42 kg (multiple readings)\n",
      "* Pulse Rate: 92 bpm, 88 bpm, 67 bpm, and 78 bpm (multiple readings)\n",
      "* Blood Pressure: 82/123 mmHg, 89/120 mmHg, 87/116 mmHg, and 71/137 mmHg (multiple readings)\n",
      "* Temperature: 39.8째C, 37.1째C, 39.1째C, and 38.4째C (multiple readings)\n",
      "* Oxygen Saturation: 94%, 91%, 98%, and 99% (multiple readings)\n",
      "\n",
      "Please note that there are multiple readings for each vital sign, which may indicate different measurements taken at different times or under different conditions.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.openai.base.OpenAI._chat in 0.25420164396825573 seconds as it raised InternalServerError: Error code: 503 - {'error': {'message': 'Service Unavailable', 'type': 'internal_server_error'}}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a synthesized response based on the query results:\n",
      "\n",
      "Dillon Lubowitz has visited our clinic four times. Here are the details of his previous visits:\n",
      "\n",
      "**Visit 1 (August 27, 2024, 19:31:30)**\n",
      "Chief Complaint: Eligendi et cum vitae ea.\n",
      "History of Present Illness (HPI): Necessitatibus eum sint earum et ut assumenda in.\n",
      "Past Family Social History (PFSH): Fuga et ut ut exercitationem dicta.\n",
      "\n",
      "**Visit 2 (August 27, 2024, 19:31:30)**\n",
      "Chief Complaint: Sit eligendi dolore dolorum quis aut sapiente.\n",
      "History of Present Illness (HPI): Recusandae et excepturi voluptates ex distinctio velit.\n",
      "Past Family Social History (PFSH): Possimus veniam et unde saepe rerum et.\n",
      "\n",
      "**Visit 3 (August 27, 2024, 19:31:30)**\n",
      "Chief Complaint: Aut consequatur iusto perspiciatis dignissimos quo neque dolorem.\n",
      "History of Present Illness (HPI): Voluptas est eaque eum unde vitae earum.\n",
      "Past Family Social History (PFSH): Nihil quaerat sed quasi voluptatem quia expedita est.\n",
      "\n",
      "**Visit 4 (August 27, 2024, 19:31:30)**\n",
      "Chief Complaint: Aut nulla est impedit ipsum.\n",
      "History of Present Illness (HPI): Possimus atque et modi eveniet.\n",
      "Past Family Social History (PFSH): Deleniti a enim quia a sint magni.\n",
      "\n",
      "Please let me know if you need any further assistance!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question = ''\n",
    "while True:\n",
    "    question = input()\n",
    "    if question == 'q':\n",
    "        break\n",
    "    response = query_engine.query(question)\n",
    "    print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
